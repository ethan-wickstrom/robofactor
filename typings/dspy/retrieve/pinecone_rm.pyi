"""
This type stub file was generated by pyright.
"""

import pinecone
from typing import List, Optional, Union
from dspy import Prediction, Retrieve

"""
Retriever model for Pinecone
Author: Dhar Rawal (@drawal1)
"""
if pinecone is None: ...
OPENAI_LEGACY = ...
ERRORS = ...

class PineconeRM(Retrieve):
    """
    A retrieval module that uses Pinecone to return the top passages for a given query.

    Assumes that the Pinecone index has been created and populated with the following metadata:
        - text: The text of the passage

    Args:
        pinecone_index_name (str): The name of the Pinecone index to query against.
        pinecone_api_key (str, optional): The Pinecone API key. Defaults to None.
        pinecone_env (str, optional): The Pinecone environment. Defaults to None.
        local_embed_model (str, optional): The local embedding model to use. A popular default is "sentence-transformers/all-mpnet-base-v2".
        openai_embed_model (str, optional): The OpenAI embedding model to use. Defaults to "text-embedding-ada-002".
        openai_api_key (str, optional): The API key for OpenAI. Defaults to None.
        openai_org (str, optional): The organization for OpenAI. Defaults to None.
        k (int, optional): The number of top passages to retrieve. Defaults to 3.

    Returns:
        dspy.Prediction: An object containing the retrieved passages.

    Examples:
        Below is a code snippet that shows how to use this as the default retriever:
        ```python
        llm = dspy.OpenAI(model="gpt-3.5-turbo")
        retriever_model = PineconeRM(openai.api_key)
        dspy.settings.configure(lm=llm, rm=retriever_model)
        ```

        Below is a code snippet that shows how to use this in the forward() function of a module
        ```python
        self.retrieve = PineconeRM(k=num_passages)
        ```
    """
    def __init__(
        self,
        pinecone_index_name: str,
        pinecone_api_key: Optional[str] = ...,
        pinecone_env: Optional[str] = ...,
        local_embed_model: Optional[str] = ...,
        openai_embed_model: Optional[str] = ...,
        openai_api_key: Optional[str] = ...,
        openai_org: Optional[str] = ...,
        k: int = ...,
    ) -> None: ...
    def forward(self, query_or_queries: Union[str, List[str]]) -> Prediction:
        """Search with pinecone for self.k top passages for query

        Args:
            query_or_queries (Union[str, List[str]]): The query or queries to search for.

        Returns:
            dspy.Prediction: An object containing the retrieved passages.
        """
        ...
