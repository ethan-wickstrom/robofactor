"""
This type stub file was generated by pyright.
"""

from typing import Any, Callable, Dict, List, Literal, Optional, Union
from dspy.adapters.base import Adapter
from dspy.clients.lm import LM
from dspy.primitives.example import Example
from dspy.primitives.module import Module
from dspy.teleprompt.bootstrap_finetune import FinetuneTeleprompter

logger = ...
class GRPO(FinetuneTeleprompter):
    def __init__(self, metric: Optional[Callable] = ..., multitask: bool = ..., train_kwargs: Optional[Union[Dict[str, Any], Dict[LM, Dict[str, Any]]]] = ..., adapter: Optional[Union[Adapter, Dict[LM, Adapter]]] = ..., exclude_demos: bool = ..., num_threads: int = ..., num_train_steps: int = ..., seed: int = ..., num_dspy_examples_per_grpo_step: int = ..., num_rollouts_per_grpo_step: int = ..., use_train_as_val: bool = ..., num_steps_for_val: int = ..., report_train_scores: bool = ..., failure_score: float = ..., format_failure_score: float = ..., variably_invoked_predictor_grouping_mode: Union[Literal["truncate"], Literal["fill"], Literal["ragged"]] = ..., variably_invoked_predictor_fill_strategy: Optional[Union[Literal["randint"], Literal["max"]]] = ...) -> None:
        ...
    
    def validate_trace_data_and_log_issues(self, trace_data: List[List[List[Dict[str, Any]]]], subsample_training_dataset: List[Example], num_teachers: int, num_samples_per_input: int, pred_signature_hash_to_ind: Dict[int, int]): # -> None:
        ...
    
    def report_validation_metrics(self, student, trainset, valset, logger, step_idx=...): # -> None:
        ...
    
    def update_shuffled_trainset(self, original_trainset): # -> None:
        ...
    
    def select_training_sample_and_update_shuffled_trainset(self, original_trainset: List[Example], train_step_idx: int) -> List[Example]:
        ...
    
    def compile(self, student: Module, trainset: List[Example], teacher: Optional[Union[Module, List[Module]]] = ..., valset: Optional[List[Example]] = ..., **kwargs) -> Module:
        ...
    


def disable_lm_cache(program: Module, lm_cache_dict: dict): # -> None:
    """Disable the LM cache for all predictors in the program."""
    ...

def recover_lm_cache(program: Module, lm_cache_dict: dict): # -> None:
    """Recover the LM caches for all predictors in the program to their original state."""
    ...

