"""
This type stub file was generated by pyright.
"""

from collections.abc import Generator

logger = ...
class BaseModule:
    def __init__(self) -> None:
        ...
    
    def named_parameters(self): # -> list[Any]:
        """
        Unlike PyTorch, handles (non-recursive) lists of parameters too.
        """
        ...
    
    def named_sub_modules(self, type_=..., skip_compiled=...) -> Generator[tuple[str, BaseModule], None, None]:
        """Find all sub-modules in the module, as well as their names.

        Say self.children[4]['key'].sub_module is a sub-module. Then the name will be
        'children[4][key].sub_module'. But if the sub-module is accessible at different
        paths, only one of the paths will be returned.
        """
        ...
    
    def parameters(self): # -> list[Any]:
        ...
    
    def deepcopy(self): # -> Self:
        """Deep copy the module.

        This is a tweak to the default python deepcopy that only deep copies `self.parameters()`, and for other
        attributes, we just do the shallow copy.
        """
        ...
    
    def reset_copy(self): # -> Self:
        """Deep copy the module and reset all parameters."""
        ...
    
    def dump_state(self): # -> dict[Any, Any]:
        ...
    
    def load_state(self, state): # -> None:
        ...
    
    def save(self, path, save_program=..., modules_to_serialize=...): # -> None:
        """Save the module.

        Save the module to a directory or a file. There are two modes:
        - `save_program=False`: Save only the state of the module to a json or pickle file, based on the value of
            the file extension.
        - `save_program=True`: Save the whole module to a directory via cloudpickle, which contains both the state and
            architecture of the model.

        If `save_program=True` and `modules_to_serialize` are provided, it will register those modules for serialization 
        with cloudpickle's `register_pickle_by_value`. This causes cloudpickle to serialize the module by value rather 
        than by reference, ensuring the module is fully preserved along with the saved program. This is useful 
        when you have custom modules that need to be serialized alongside your program. If None, then no modules 
        will be registered for serialization.

        We also save the dependency versions, so that the loaded model can check if there is a version mismatch on
        critical dependencies or DSPy version.

        Args:
            path (str): Path to the saved state file, which should be a .json or .pkl file when `save_program=False`,
                and a directory when `save_program=True`.
            save_program (bool): If True, save the whole module to a directory via cloudpickle, otherwise only save
                the state.
            modules_to_serialize (list): A list of modules to serialize with cloudpickle's `register_pickle_by_value`.
                If None, then no modules will be registered for serialization.

        """
        ...
    
    def load(self, path): # -> None:
        """Load the saved module. You may also want to check out dspy.load, if you want to
        load an entire program, not just the state for an existing program.

        Args:
            path (str): Path to the saved state file, which should be a .json or a .pkl file
        """
        ...
    


